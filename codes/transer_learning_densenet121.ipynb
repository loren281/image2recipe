{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26462,"status":"ok","timestamp":1688279929547,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"yWoNipUybcyS","outputId":"da40a07d-3ee9-4344-e6e4-e5e086c6ebe4"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6766,"status":"ok","timestamp":1688279939032,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"Nnr55KOtb4ex"},"outputs":[],"source":["import time\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","import torchvision\n","from torchvision import transforms, models\n","from sklearn.model_selection import train_test_split\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":796,"status":"ok","timestamp":1688279949888,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"2n24h7_ZcG05"},"outputs":[],"source":["# Dataset and dataloader\n","\n","def get_dataset(batch_size):\n","    train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                          transforms.RandomResizedCrop(224),\n","                                          transforms.RandomHorizontalFlip(),\n","                                          transforms.ToTensor(),\n","                                          transforms.Normalize([0.485, 0.456, 0.406],\n","                                                                [0.229, 0.224, 0.225])])\n","\n","    # Normalize the test set same as training set without augmentation\n","    eval_transforms = transforms.Compose([transforms.Resize(255),\n","                                          transforms.CenterCrop(224),\n","                                          transforms.ToTensor(),\n","                                          transforms.Normalize([0.485, 0.456, 0.406],\n","                                                              [0.229, 0.224, 0.225])])\n","\n","    validation_size = 0.2\n","\n","    # Split to train, test, validation\n","    trainval = torchvision.datasets.Food101(root='./datasets', split='train', download=True, transform=train_transforms)\n","    trainset, valset = train_test_split(trainval, test_size=validation_size)\n","    testset = torchvision.datasets.Food101(root='./datasets', split='test', download=True, transform=eval_transforms)\n","\n","    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n","    \n","    return train_loader, test_loader, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1006,"status":"ok","timestamp":1688279953914,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"W0tYWCqld8Tv"},"outputs":[],"source":["# Transfer learning - change DenseNet's final layer\n","\n","def define_model():\n","\n","  model = models.densenet121(weights='IMAGENET1K_V1')\n","\n","  for param in model.parameters():\n","      param.requires_grad = False\n","\n","  model.classifier = nn.Sequential(nn.Linear(1024,101)\n","                                  # nn.LeakyReLU(),\n","                                  # nn.Linear(512,101)\n","                              )\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1688279957351,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"vLwgBnWtmU2A"},"outputs":[],"source":["# Hyperparameters\n","\n","num_epochs = 30\n","learning_rate = 0.001\n","batch_size = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":426,"status":"ok","timestamp":1688279985673,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"q6VdcdsjeJ0j"},"outputs":[],"source":["# Train\n","\n","def train(num_epochs, train_loader, val_loader, model, optimizer, criterion):\n","    model = model.to(device)\n","\n","    start = time.time()\n","\n","    val_acc_history = []  # List to store validation accuracy history\n","    train_acc_history = []  # List to store training accuracy history\n","\n","    num_of_batches = len(train_loader) \n","\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","\n","        model.train()\n","        running_loss = 0.0\n","        running_corrects = 0 \n","\n","        for i, data in enumerate(train_loader): \n","            inputs, labels = data\n","            inputs = inputs.to(device) \n","            labels = labels.to(device)\n","\n","            # Forward\n","            outputs = model(inputs) \n","            loss = criterion(outputs, labels)\n","\n","            # Backward\n","            optimizer.zero_grad() \n","            loss.backward() \n","            optimizer.step()\n","\n","            # Find loss and accuracy\n","            _, train_preds = torch.max(outputs, 1)  # Get the predicted labels\n","            running_loss += loss.item() * inputs.size(0)  # Update the running loss\n","            running_corrects += torch.sum(train_preds == labels)  # Update the number of correct predictions\n","\n","            # Print status every 100 steps\n","            if (i + 1) % 100 == 0:\n","                time_cost = time.time() - start\n","                print('Epoch [{}/{}], Step [{}/{}], Time:{}'.format(epoch + 1, num_epochs, i + 1, num_of_batches,\n","                                                                     time_cost))\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = running_corrects.double() / len(train_loader.dataset) * 100\n","\n","        train_acc_history.append(epoch_acc)\n","\n","        model.eval()\n","\n","        running_val_loss = 0.0 \n","        running_val_corrects = 0 \n","\n","        # Find score on validation\n","        for i, data in enumerate(val_loader):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            with torch.no_grad():\n","\n","                # Forward\n","                val_outputs = model(inputs) \n","                val_loss = criterion(val_outputs, labels)\n","\n","                _, val_preds = torch.max(val_outputs, 1)  # Get the predicted labels\n","                running_val_loss += val_loss.item() * inputs.size(0)  # Update the running loss\n","                running_val_corrects += torch.sum(val_preds == labels)  # Update the number of correct predictions\n","\n","        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n","        epoch_val_acc = running_val_corrects.double() / len(val_loader.dataset) * 100\n","\n","        # Avg accuracy and loss for each epoch\n","        time_cost = time.time() - start\n","        print('Done Epoch [{}/{}], Time:{}'.format(epoch + 1, num_epochs, time_cost))\n","        print('-' * 10)\n","        print('Train Loss: {:.4f} Train Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n","        print('Test Loss: {:.4f} Test Acc: {:.4f}'.format(epoch_val_loss, epoch_val_acc))\n","\n","        # Save the model if the validation accuracy improves\n","        if epoch_val_acc > best_acc:\n","            print(\"saved model with higher accuracy\")\n","            best_acc = epoch_val_acc\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/dl_project/models/food101_less_loss.pth')\n","\n","        val_acc_history.append(epoch_val_acc)\n","\n","        model.train()  # Set the model back to training mode\n","\n","    return train_acc_history, val_acc_history\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":488233,"status":"ok","timestamp":1688280478212,"user":{"displayName":"Loren Tzveniashvily","userId":"07779808463668063503"},"user_tz":-180},"id":"UXq1rmh_evm_","outputId":"dd7f4d82-1a2a-42a5-d187-e5a15bc0bdb3"},"outputs":[],"source":["model = define_model()\n","\n","optimizer = torch.optim.Adam(model.classifier.parameters(), lr=learning_rate, betas=[0.9, 0.999])\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","train_loader, test_loader, val_loader = get_dataset(batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVZju6_XEAwm","outputId":"723393e8-02eb-41ba-bd2b-9bf3124ac3bc"},"outputs":[],"source":["# Display graph of train and validation accuracy\n","\n","train_acc_history, val_acc_history = train(num_epochs, train_loader, val_loader, model, optimizer, criterion)\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot(range(num_epochs), train_acc_history, label='train accuracy')\n","ax.plot(range(num_epochs), val_acc_history, label='validation accuracy')\n","ax.set_xlabel(\"Epochs\")\n","ax.set_ylabel(\"Accuracy\")\n","ax.grid()\n","ax.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKSWLZnQewGJ"},"outputs":[],"source":["\n","# Save the final model's weights\n","\n","torch.save(model.state_dict(), '/content/drive/MyDrive/dl_project/models/final_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test on testset\n","\n","model.eval()\n","\n","test_loss = 0.0\n","test_accuracy = 0.0\n","\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader):\n","        images, labels = data\n","        images = images.to(device) \n","        labels = labels.to(device)\n","\n","        # Forward\n","        outputs = model(images)\n","        batch_loss = criterion(outputs, labels)\n","        test_loss += batch_loss.item()\n","\n","        # Find top5 accuracy score\n","        _, top_labels = outputs.topk(5, dim=1)\n","        labels = labels.view(-1, 1)\n","\n","        results = top_labels == labels\n","        results = results.sum(1)\n","\n","        # Avg accuracy and loss for each epoch\n","        test_accuracy += torch.mean(results.float()).item()\n","        avg_test_accuracy = test_accuracy / (i + 1)\n","        avg_test_loss = test_loss / (i + 1)\n","\n","        time_cost = time.time() - start\n","        print('Step [{}/{}], Loss: {:.4f}, Accuracy Top5: {:.3%}, Time:{}'.format(i + 1, len(test_loader),\n","                                                                                   avg_test_loss, avg_test_accuracy,\n","                                                                                   time_cost))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":0}
